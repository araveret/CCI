getwd()
rm(list = ls()); gc()
getwd()
setwd("C:/Users/josdavis/Documents")
data = read.table("titanic.csv", sep = ",", header = TRUE)
# Inspect a dataframe
str(data)
head(data, 8)
summary(data)
# Inspect a variable
str(data$pclass)
head(data$pclass, 8)
summary(data$pclass)
write.table(data, "newdata.csv", sep = ",", row.names = FALSE)
str(data$age)
head(data$age, 8)
summary(data$age)
data$age2 = data$age
head(data)
rm(list=ls()) # clear the workspace
set.seed(973487) # Ensures you can repeat the results
library(caret)
library(rpart)
# Loac and partition data
setwd("C:/Users/josdavis/Documents")
titanic = read.table("titanic.csv", sep = ",", header = TRUE)
idx = createDataPartition(titanic$survived, p = 0.50,list=FALSE)
train = titanic[idx,]
test = titanic[-idx,]
model1 = rpart(as.factor(survived) ~ pclass + sex + age + sibsp, data = train)
library(partykit)
plot(as.party(model1))
round(model1$variable.importance, 1)
pred1.is = predict(model1, newdata = train, type = "class")
pred1.os = predict(model1, newdata = test, type = "class")
head(pred1.is)
sum(pred1.is == train$survived) / length(train$survived)
sum(pred1.os == test$survived) / length(test$survived)
table(pred1.is, train$survived)
prop.table(pred1.is, train$survived)
prop.table(table(pred1.is, train$survived))
prop.table(round(table(pred1.is, train$survived), 2)
)
prop.table(table(pred1.is, train$survived), 2)
prop.table(table(pred1.is, train$survived), 1)
prop.table(table(pred1.is, train$survived)) # % of values in each bucket
round(prop.table(table(pred1.is, train$survived)), 2) # % of values in each bucket
100*round(prop.table(table(pred1.is, train$survived)), 2) # % of values in each bucket
100*round(prop.table(table(pred1.is, train$survived), 1)) # % of predicted values which are correctedly
100*round(prop.table(table(pred1.is, train$survived), 2)) # % of actual results correctly predicted
summary(data$age[data$age>30])
summary(data$age)
summary(data$age2)
setwd("C:/Users/josdavis/Documents")
data = read.table("titanic.csv", sep = ",", header = TRUE)
summary(data$age[data$age>30])
head(data$age[data$age>30])
summary(data$age[data$age>30])
summary(data$pclass)
summary(data$age[data$age>30 & data$pclass == "3rd"])
summary(data)
summary(data[data$age>30 & data$pclass == "3rd", ])
dim(data[data$age>30 & data$pclass == "3rd", ])
dim(data[data$age>30 & data$pclass == "3rd", ])[1]
x = dim(data[data$age>30 & data$pclass == "3rd", ])
x
dim(data[data$age>30 & data$pclass == "3rd", ])[1]
dim(data[1])
dim(data)[1]
dim(data[data$age>30 & data$pclass == "3rd", ])[1] / dim(data)[1]
subs = data[data$age>30 & data$pclass == "3rd", ]
summary(subs) # Only take the 3rd class people over 30
dim(subs)[1] / dim(data)[1] # % of observations in the subsetted data
rm(list=ls()) # clear the workspace
set.seed(973487) # Ensures you can repeat the results
library(caret)
library(rpart)
# Load and partition data
setwd("C:/Users/josdavis/Documents")
titanic = read.table("titanic.csv", sep = ",", header = TRUE)
idx = createDataPartition(titanic$survived, p = 0.50,list=FALSE)
train = titanic[idx,]
test = titanic[-idx,]
# Train the tree
model1 = rpart(as.factor(survived) ~ pclass + sex + age + sibsp, data = train)
# Plot the tree
library(partykit)
plot(as.party(model1))
round(model1$variable.importance, 1)
pred1.is = predict(model1, newdata = train, type = "class")
pred1.os = predict(model1, newdata = test, type = "class")
sum(pred1.is == train$survived) / length(train$survived)
sum(pred1.os == test$survived) / length(test$survived)
table(pred1.is, train$survived)
100*round(prop.table(table(pred1.is, train$survived)), 2) # % of values in each bucket
100*round(prop.table(table(pred1.is, train$survived)), 3) # % of values in each bucket
round(prop.table(table(pred1.is, train$survived)), 2) # % of values in each bucket
round(prop.table(table(pred1.is, train$survived), 1), 2) # Across then down
round(prop.table(table(pred1.is, train$survived), 2)) # Down then across
prop.table(table(pred1.is, train$survived), 2)# Down then across
round(prop.table(table(pred1.is, train$survived), 2), 2) # Down then across
?ls
rm(list = ls())
gc()
getwd()
setwd("C:/Users/josdavis/Documents")
setwd("C:/Users/josdavis/Downloads")
getwd()
setwd("C:/Users/josdavis/Documents")
data = read.table("titanic.csv", sep = ",", header = TRUE)
str(data)
head(data, 8)
summary(data)
str(data$age)
head(data$age, 8)
summary(data$age)
write.table(data[1:100,], "newdata.csv", sep = ",", row.names = FALSE)
getwd()
titanic = read.table("titanic.csv", sep = ",", header = TRUE)
sample = read.table("titanic.csv", sep = ",", header = TRUE)
save.image("titanic.RData")
rm(list = ls()); gc()
load("titanic.RData")
rm(sample, titanic)
gc()
data$age2 = data$age
head(data)
subs = data[data$age>30 & data$pclass == "3rd", ]
summary(subs) # Only take the 3rd class people over 30
summary(data)
View(data)
View(subs)
dim(subs)
dim(subs)[1]
dim(subs)[1] / dim(data)[1] # % of observations in the subsetted data
summary(data$age)
mean(data$age2)
mean(data$age2, na.rm = TRUE)
data$age2[is.na(data$age2)]
is.na(data$age2)
is.na(data$age2)
data$age2[is.na(data$age2)]
rm(list=ls()) # clear the workspace
set.seed(973487) # Ensures you can repeat the results
library(caret)
library(rpart)
setwd("C:/Users/josdavis/Documents")
titanic = read.table("titanic.csv", sep = ",", header = TRUE)
idx = createDataPartition(titanic$survived, p = 0.50,list=FALSE)
train = titanic[idx,]
test = titanic[-idx,]
model1 = rpart(as.factor(survived) ~ pclass + sex + age + sibsp, data = train)
library(partykit)
plot(as.party(model1))
names(model1)
round(model1$variable.importance, 1)
pred1.is = predict(model1, newdata = train, type = "class")
pred1.os = predict(model1, newdata = test, type = "class")
head(pred1.is)
head(train$survived)
head(train$survived)
sum(pred1.is == train$survived) / length(train$survived)
sum(pred1.os == test$survived) / length(test$survived)
table(pred1.is, train$survived)
table(pred1.os, test$survived)
round(prop.table(table(pred1.is, train$survived)), 2) # % of values in each bucket
prop.table(table(pred1.is, train$survived)) # % of values in each bucket
round(prop.table(table(pred1.is, train$survived), 1), 2) # Across (based on predictions)
round(prop.table(table(pred1.is, train$survived), 2), 2) # Down (based on actuals)
?predict
?predict.rpart
pred1.is = predict(model1, newdata = train, type = "prob")
head(pred1.is)
head(pred1.is[,2])
head(pred1.is[,1])
pred1.is = predict(model1, newdata = train, type = "vector")
head(pred1.is)
datasets()
dataset()
data()
data(package = .packages(all.available = TRUE))
datasets()
UN
data()
BOD
UN
data(package = .packages(all.available = TRUE))
cynipids
data(cynipids)
load(cynipids)
load(url('http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.sav'))
View(titanic3)
fruits = c('apple', 'banana', 'cherry', 'plum')
len(fruits)
length(fruits)
for (i in 1:length(fruits)){
print fruits[i]
}
fruits = c('apple', 'banana', 'cherry', 'plum')
for (i in 1:length(fruits)){
print fruits[i]
}
for (i in 1:length(fruits)){
fruits[i]
}
print(fruits[1])
for (i in 1:length(fruits)){
print(fruits[i])
}
var1 = 10
if (var1 > 5){
print("More than 5")
}
else(var1 < 5){
print("Less than 5")
}
else{
print("5")
}
if(var1 > 5){
print("More than 5")
}
elseif(var1 < 5){
print("Less than 5")
}
elseif{
print("5")
}
var1 = 10
if (var1 > 5) {
print("More than 5")
} else (var1 < 5){
print("Less than 5")
} else {
print("5")
}
if (var1 > 5) {
print("More than 5")
} else if (var1 < 5){
print("Less than 5")
} else {
print("5")
}
if (var1 > 5) {
print("More than 5")
} else if (var1 < 5){
print("Less than 5")
} else {
print("5")
}
load("~/Projects/VA/Task 3/R Scripts/OPM Import.R")
install.packages("swirl")
library(swirl)
install_from_swirl("Regression Models")
rm(list=ls()); gc()     # clear the workspace
set.seed(973487)        # Ensures you can repeat the results
library(rpart)          # For creating the tree
library(partykit)       # For plotting the tree
setwd("C:/Users/josdavis/Documents/Personal/GitHub/CCI")
# Get the data
data <- read.csv("titanic.csv", header = TRUE)
data$survived = data$survived == 'survived'
data <- na.omit(data)
# Split into training and testing sets
idxs <- runif(nrow(data)) < 0.7   # Random Indices
train <- data[idxs, ]             # Training set
test  <- data[!idxs, ]            # Testing set
rm(idxs)
model <- rpart(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = train,
method = "class")
# Generate predictions (both probabilities and class predictions)
test$prediction <- predict(model, type = "prob", newdata = test)[,2] > 0.5
# Acccuracy in terms of classification rate (with 0.5 threshhold)
sum(test$prediction == test$survived) / nrow(test)
data.frame(maxdepth = c(1, 2, 3, 4, 5, 6, 7, 8))
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data,
metric = "Accuracy",
method = "rpart2",
trainControl = trainControl(method = "cv", number = 5),
tuneGrid = data.frame(maxdepth = c(2, 3, 4, 5, 6, 7, 8)))
library(caret)
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data,
metric = "Accuracy",
method = "rpart2",
trainControl = trainControl(method = "cv", number = 5),
tuneGrid = data.frame(maxdepth = c(2, 3, 4, 5, 6, 7, 8)))
warnings()
is.na(data)
sum(is.na(data)0
sum(is.na(data))
tune_results$bestTune
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data,
metric = "Accuracy",
method = "rpart2")
tune_results$bestTune
tune_results
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data,
method = "rpart2")
tune_results
tune_results$bestTune
tune_results$parameters
tune_results$grid
tune_results$method
tune_results$modelInfo
tune_results$modelInfo$grid
tune_results$results
tune_results$results$maxdepth
plot(tune_results$results$maxdepth, tune_results$results$Accuracy)
tune_results$results
tune_results
?trainControl
tc <- trainControl(method = 'cv', number = 5)
tune_results
m = "cv"
grep1("cv", m)
grepl("cv", m)
grepl("cdv", m)
grepl("cv", m)
tg <- data.frame(maxdepth = c(2, 3, 4, 5))
tg <- data.frame(maxdepth = c(2, 3, 4, 5))
tg
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data,
method = "rpart2",
trainControl = tc,
tuneGrid = tg)
tune_results
data <- read.csv("titanic.csv", header = TRUE)
head(data)
data$survived = data$survived == 'survived'
data2 <- na.omit(data)
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data2,
method = "rpart2")
tune_results
tc <- trainControl(method = 'cv', number = 5)
# tuneGRid specifies the range of values to evalaute the model across
# Here I am specifying a wider range of max tree depths to evalaute my tree across
# NOTE: the column name for the dataframe must be spelled the same as the argument to the function
tg <- data.frame(maxdepth = c(2, 3, 4, 5))
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data2,
method = "rpart2",
trainControl = tc,
tuneGrid = tg)
str(data2)
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data2,
method = "rpart2",
trainControl = tc)
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data2,
method = "rpart2",
tuneGrid = tg)
tune_results
tg <- data.frame(maxdepth = c(2, 3, 4, 5, 6, 7, 8, 9, 10))
tg <- data.frame(maxdepth = c(2, 3, 4, 5, 6, 7, 8, 9, 10))
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data2,
method = "rpart2",
tuneGrid = tg)
# Plot the results of the tuning
plot(tune_results$results$maxdepth, tune_results$results$Accuracy)
tune_results$bestTune
tg <- data.frame(maxdepth = c(2, 4, 6, 7, 8, 10, 15, 20, 25))
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data2,
method = "rpart2",
tuneGrid = tg)
# Plot the results of the tuning
plot(tune_results$results$maxdepth, tune_results$results$Accuracy)
tune_results$results
tune_results
?trainControl
tc <- trainControl(method = 'boot', p = 0.75, number = 10)
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data2,
method = "rpart2",
tuneGrid = tg,
trControl = tc)
plot(tune_results$results$maxdepth, tune_results$results$Accuracy)
tc <- trainControl(method = 'cv', number = 10)
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data2,
method = "rpart2",
tuneGrid = tg,
trControl = tc)
plot(tune_results$results$maxdepth, tune_results$results$Accuracy)
tune_results$bestTune
tune_results$bestTune
tree_depth <- tune_results$bestTune
data <- read.csv("titanic.csv", header = TRUE)
data$survived = data$survived == 'survived'
data <- na.omit(data)
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data2,
method = "rpart2",
tuneGrid = tg)
tune_results <-train(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = data2,
method = "rpart2",
tuneGrid = tg,
trControl = tc)
tuned_model <- rpart(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = train,
method = "class",
control = rpart.control(maxdepth = tune_results$bestTune))
tuned_model
tuned_model$method
tuned_model$control
tuned_model$control$maxdepth
test$prediction <- predict(tune_model, type = "prob", newdata = test)[,2] > 0.5
test$prediction <- predict(tuned_model, type = "prob", newdata = test)[,2] > 0.5
test$prediction
sum(test$prediction == test$survived) / nrow(test)
tree
tree <- rpart(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = train,
method = "class",
control = rpart.control(minsplit = 30))
library(partykit)
plot(as.party(tree))
library(rpart.plot)
prp(tree)
library(rattle)
fancyRpartPlot(tree)
?fancyRpartPlot
?prp
rm(list=ls()); gc()     # clear the workspace
set.seed(973487)        # Ensures you can repeat the results
library(rpart)          # For creating the tree
library(partykit)       # For plotting the tree
setwd("C:/Users/josdavis/Documents/Personal/GitHub/CCI")
# Get the data
data <- read.csv("titanic.csv", header = TRUE)
data <- read.csv("titanic.csv", header = TRUE)
data$survived = data$survived == 'survived'
head(data)
idxs <- runif(nrow(data)) < 0.7   # Random Indices
idxs
train <- data[idxs, ]             # Training set
test  <- data[!idxs, ]            # Testing set
rm(idxs, data)
summary(train)
tree <- rpart(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = train,
method = "class")
tree
summary(tree)
tree$variable.importance
plot(tree)
text(tree)
library(partykit)
as.party(tree)
plot(as.party(tree))
library(rpart.plot)
prp(tree)
?prp
library(rattle)
fancyRpartPlot(tree)
tree <- rpart(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = train,
method = "class",
control = rpart.control(maxdepth = 4))
?rpart
?rpart.control
predict(tree, type = "prob", newdata = test)[,2]
predict_proba > 0.5
predict(tree, type = "prob", newdata = test)[,2] > 0.5
test$predict_proba <- predict(tree, type = "prob", newdata = test)[,2]
test$prediction <- predict_proba > 0.5
test$prediction <- test$predict_proba > 0.5
sum(test$prediction == test$survived) / nrow(test)
table(test$prediction, test$survived)
prop.table(table(test$prediction, test$survived), 2)
test_lived = test[test$survived,]
sum(test_lived$prediction == test_lived$survived) / nrow(test_lived)
test_died = test[!test$survived,]
sum(test_died$prediction == test_died$survived) / nrow(test_died)
rf <- randomForest(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = train,
na.action = na.omit)
library(randomForest)   # For creating the forest
rf <- randomForest(as.factor(survived) ~ pclass + sex + age + sibsp + parch,
data = train,
na.action = na.omit)
rf$importance
